{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Notebook Walk-through: </center>\n",
    "    \n",
    "<center>Fine-Tuning BERT - Optimizer Considerations and Layer Freezing\n",
    "</center></h2>\n",
    "\n",
    "In this notebook we discuss some aspects of BERT Fine-tuning for a specific task. We choose a text classification as an example. We will highlight various aspects you may encounter.\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "* play with BERT (Hugging Face implementation): Tokenization, Layers and Output Dimensions  \n",
    "* build a sentiment classifier with BERT from scratch and discuss a couple of options you may have\n",
    "* train the network with various configurations and make observations that will hopefully be helpful\n",
    "\n",
    "Note that a lot of the content will be delivered through live experimentation in the walkthrough session, and it will not be recorded in the notebook. Please watch the recording. \n",
    "\n",
    "Also, note that we are not attempting to reach state of the art by any means. The purpose of the notebook is to highlight some of the issues you may want to consider when fine-tuning BERT.\n",
    "\n",
    "We start with a few common imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for presence of a GPU. We'll need that (or better) if we use transformer models like BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's specify the versions that we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting the data\n",
    "\n",
    "We'll use the IMDB dataset, available from tensorflow_datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
      "INFO:absl:Load dataset info from /home/joachim/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Reusing dataset imdb_reviews (/home/joachim/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset imdb_reviews for split ('train[:80%]', 'test[80%:]'), from /home/joachim/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:80%]', 'test[80%:]'),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's some create train examples and test examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(20000)))\n",
    "test_examples_batch, test_labels_batch = next(iter(test_data.batch(5000)))\n",
    "#train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
       "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
       "       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n",
       "       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 1])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the model input with the BERT Tokenizer\n",
    "\n",
    "We use the 'bert-base-cased' from Huggingface as the underlying BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few training and test examples. For training time purposes, let's define a relatively short maximum length. We may modify the numbers later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = 2500\n",
    "num_test_examples = 500\n",
    "num_tiny_set = 5\n",
    "\n",
    "max_length = 80\n",
    "\n",
    "x_train = tokenizer([str(x.numpy())[2:] for x in train_examples_batch[:num_train_examples]], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = train_labels_batch[:num_train_examples]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test = tokenizer([str(x.numpy())[2:] for x in test_examples_batch[:num_test_examples]], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_test = test_labels_batch[:num_test_examples]\n",
    "\n",
    "\n",
    "x_tiny = tokenizer([str(x.numpy())[2:] for x in test_examples_batch[:num_tiny_set]], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_tiny = test_labels_batch[:num_tiny_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the class imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of positive examples:  0.494\n"
     ]
    }
   ],
   "source": [
    "print('ratio of positive examples: ', np.sum(y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, slightly more negative examples in train set.\n",
    "\n",
    "What did the tokenizer do?\n",
    "\n",
    "The tokenizer created input ids, token type ids, and masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2500, 80), dtype=int32, numpy=\n",
       "array([[  101,  1188,  1108, ...,  9283,  1127,   102],\n",
       "       [  101,   146,  1138, ...,  1104,  1184,   102],\n",
       "       [  101, 10852,  6810, ...,  1113,  1103,   102],\n",
       "       ...,\n",
       "       [  101,  1247,  1110, ...,  1105, 13952,   102],\n",
       "       [  101,  1327,  1103, ...,  6188, 11074,   102],\n",
       "       [  101,  1188,  2523, ..., 12118,  8057,   102]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2500, 80), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2500, 80), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprises...\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "* What are the purpose of each component?\n",
    "* Why do the input ids all start off with 101?\n",
    "\n",
    "### 3. BERT\n",
    "\n",
    "Let's look at the first 25 weights in BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_bert_model/bert/embeddings/word_embeddings/weight:0',\n",
       " 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0',\n",
       " 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0',\n",
       " 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'tf_bert_model/bert/embeddings/LayerNorm/beta:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0',\n",
       " 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.name for x in bert_model.weights][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "* Does this make sense?\n",
    "\n",
    "It sure does...\n",
    "\n",
    "What are the outputs of bert_model, when applied to data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_out = bert_model(x_tiny, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 80, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_out[0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_out[1].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_out[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768]),\n",
       " TensorShape([5, 80, 768])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in bert_out[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "* What are the interpretations of the 3 outputs?\n",
    "* Are the respective dimensions as expected?\n",
    "\n",
    "### 4. Building our Classification Model\n",
    "\n",
    "Let's build our classification model from scratch and run a few configurations.\n",
    "\n",
    "In particular, we will consider:\n",
    "\n",
    "* Optimizer choices\n",
    "* number of bert layers to be re-trained\n",
    "* effects of freezing and unfreezing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(hidden_size = 200, \n",
    "                                train_layers = -1, \n",
    "                                optimizer=tf.keras.optimizers.Adam()):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Let's keep it simple and don't add dropout, layer norms, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                  'token_type_ids': token_type_ids,\n",
    "                  'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "\n",
    "\n",
    "    classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(bert_out[0])\n",
    "\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, name='hidden_layer')(classification_token)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n",
    "                                          outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=optimizer,\n",
    "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                            metrics='accuracy')\n",
    "\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Experimentation\n",
    "\n",
    "Let us compare a few configurations:\n",
    "\n",
    "* 'default': Adam Optimizer with default parameters (lr=0.001), all BERT layers fine-tuned \n",
    "* 'smaller learning rate': Adam Optimizer with lr=0.00005 parameters, all BERT layers fine-tuned \n",
    "* 'frozen': Adam Optimizer with default parameters, all BERT layers frozen\n",
    "\n",
    "#### 5.1 Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = create_classification_model()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 70s 225ms/step - loss: 0.8652 - accuracy: 0.5136 - val_loss: 0.7540 - val_accuracy: 0.5220\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.7246 - accuracy: 0.5144 - val_loss: 0.6995 - val_accuracy: 0.4780\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 69s 220ms/step - loss: 0.7111 - accuracy: 0.4900 - val_loss: 0.6922 - val_accuracy: 0.5220\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 68s 219ms/step - loss: 0.7058 - accuracy: 0.5032 - val_loss: 0.6933 - val_accuracy: 0.4780\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 68s 219ms/step - loss: 0.7041 - accuracy: 0.5020 - val_loss: 0.6926 - val_accuracy: 0.5220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9974479b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n",
    "                         y_test),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)\n",
    "\n",
    "#classification_model([x.input_ids, x.token_type_ids, x.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.5356468 ],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674],\n",
       "       [0.53564674]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
    "                             batch_size=8, \n",
    "                             steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this? All essentially the same prediction? And basically not better than always predicting the majority class for each example? It may seem like \"BERT is no good for this task\"?!\n",
    "\n",
    "Careful, not so! There are a number of changes one can consider:\n",
    "\n",
    "* Change the optimizer configuration\n",
    "* Freeze some BERT layers - maybe for the entire training cycle or for thye first few epochs. \n",
    "* Add more data\n",
    "\n",
    "\n",
    "#### 5.2 Lower Learning Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 71s 226ms/step - loss: 0.5481 - accuracy: 0.7224 - val_loss: 0.4826 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.3149 - accuracy: 0.8676 - val_loss: 0.4882 - val_accuracy: 0.7740\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.1241 - accuracy: 0.9532 - val_loss: 0.6065 - val_accuracy: 0.7880\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.0627 - accuracy: 0.9776 - val_loss: 0.8567 - val_accuracy: 0.7700\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.8834 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.3064364e-04],\n",
       "       [6.8027135e-03],\n",
       "       [1.4993896e-02],\n",
       "       [9.9996924e-01],\n",
       "       [9.9966812e-01],\n",
       "       [9.9994528e-01],\n",
       "       [1.6548770e-03],\n",
       "       [2.1150764e-03],\n",
       "       [8.5419603e-03],\n",
       "       [2.0312648e-02],\n",
       "       [3.9322700e-04],\n",
       "       [9.9739861e-01],\n",
       "       [9.9916089e-01],\n",
       "       [4.6210135e-03],\n",
       "       [9.9998915e-01],\n",
       "       [5.3805154e-04]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del classification_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del bert_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "classification_model = create_classification_model(optimizer=tf.keras.optimizers.Adam(0.00005))\n",
    "\n",
    "classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n",
    "                         y_test),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)\n",
    "\n",
    "classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
    "                             batch_size=8, \n",
    "                             steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seemed to work! Looks like the learning rate really mattered! (Of course, we have not focused here on finding the model for the test accuracy. We simply wanted to 'get it to work').\n",
    "\n",
    "#### 5.3 Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 0.7145 - accuracy: 0.6108 - val_loss: 0.5968 - val_accuracy: 0.6660\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 0.6247 - accuracy: 0.6588 - val_loss: 0.5721 - val_accuracy: 0.7040\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 0.5958 - accuracy: 0.6688 - val_loss: 0.5625 - val_accuracy: 0.7080\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 0.5962 - accuracy: 0.6764 - val_loss: 0.5919 - val_accuracy: 0.6680\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 0.5894 - accuracy: 0.6816 - val_loss: 0.5595 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4683084 ],\n",
       "       [0.24332495],\n",
       "       [0.71891725],\n",
       "       [0.94044155],\n",
       "       [0.6260087 ],\n",
       "       [0.76680475],\n",
       "       [0.39689186],\n",
       "       [0.73443514],\n",
       "       [0.5678517 ],\n",
       "       [0.3078529 ],\n",
       "       [0.22237189],\n",
       "       [0.67680615],\n",
       "       [0.8657147 ],\n",
       "       [0.23996763],\n",
       "       [0.51509434],\n",
       "       [0.27128804]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del classification_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del bert_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "classification_model = create_classification_model(train_layers=0)\n",
    "\n",
    "classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n",
    "                         y_test),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)\n",
    "\n",
    "classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
    "                             batch_size=8, \n",
    "                             steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That 'worked' too! As expected, the final validation loss is larger and the validation accuracy is smaller though.\n",
    "\n",
    "**Questions:**\n",
    "* is that expected? \n",
    "* What else is different?\n",
    "\n",
    "But either way, all of these parameters seem to be interrelated. Experiment!\n",
    "\n",
    "### 6. Conclusions \n",
    "\n",
    "While one has to be careful to generalize from one (truncated) dataset, the pattern is pretty clear: it is not enough to simply define the model and see what you get. Some investigation needs to be devoted to making sure that the combination of model details, optimizer configurations, and data work.\n",
    "\n",
    "One big tell is if a BERT model is not better than ~'pick the majority class' or close to it, while other models perform better. \n",
    "\n",
    "One should also say that there are other things to try in the learning phase, but the point of this notebook was to point out a few obvious issues. Previous students ran into precisely these issues!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
