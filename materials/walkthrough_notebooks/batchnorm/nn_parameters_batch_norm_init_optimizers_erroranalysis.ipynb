{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'returnToTop'></a>\n",
    "\n",
    "# Table of contents\n",
    "  * A. [What's so important about NN model parameters?](#introToModelParams)  \n",
    "  * B. [Let's create our base model](#createOurModel)\n",
    "  * C. [Layer Activation](#layerActivation)  \n",
    "  * D. [Weight Initialization](#initializationFunctions)  \n",
    "  * E. [Optimizers](#optimizers) \n",
    "  * F. [Normalization](#batchNormalization) \n",
    "  * G. [Bonus Section](#errorAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'introToModelParams'></a>\n",
    "# A. What's so important about NN model parameters?\n",
    "\n",
    "Having appropriate model features can mean the difference being a model being able to learn effectively or not.  In the early 2000's neural net models suffered from the vanishing / exploding gradient problem.  Incremental innovations led to discoveries to overcome that problem, some of which we'll introduce here.  Most of these are considered de regueur today but at the time they were each revolutionary.\n",
    "\n",
    "In this lesson, we'll learn about some important model choices such as:\n",
    "  * layer activation choice\n",
    "  * initialization of weights\n",
    "  * optimizers\n",
    "  * normalization strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"2.\"))\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# Keras libraries\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import layers, backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend\n",
    "assert(tf.__version__.startswith(\"2.\"))\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "# Tensorboard\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For error analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model description\n",
    "\n",
    "We will develop a model with a word input and predicting the part of speech.  Our dataset will be a modified version of mobypos.txt from the Gutenberg project: https://archive.org/details/mobypartofspeech03203gut\n",
    "\n",
    "We've taken the original part of speech corpus (which had over 100 POS classes) and filtered it to only:  (1) 6 parts of speech  (2) words contained in the GloVe embeddings corpus.\n",
    "\n",
    "Our goal is to see if a model leveraging GloVe can accurately predict the part of speech given in our training Moby corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n"
     ]
    }
   ],
   "source": [
    "# Point to your existing GloVe download dataset from a3\n",
    "# Note:  This assumes you've already run the glove commands to download glove for a3!\n",
    "! if [[ ! -e data ]]; then ln -s ../../../assignment/a3/data .; fi\n",
    "\n",
    "# Point to glove_helper utility in a3\n",
    "! if [[ ! -e glove_helper.py ]]; then     ln -s ../../../assignment/a3/glove_helper.py .; fi\n",
    "\n",
    "# Point to w266_common in a3\n",
    "! if [[ ! -e w266_common ]]; then     ln -s ../../../assignment/a3/w266_common .; fi\n",
    "\n",
    "import glove_helper; reload(glove_helper)\n",
    "embedding_dim = 100  # 50, 100, 200, 300 dim are available\n",
    "\n",
    "hands = glove_helper.Hands(ndim=embedding_dim)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our downloaded GloVe shape:  (400003, 100)\n"
     ]
    }
   ],
   "source": [
    "# We can load a pre-trained embedding matrix into Keras as follows (using GloVe)\n",
    "print('Our downloaded GloVe shape:  {}'.format(hands.W.shape))\n",
    "\n",
    "# Create a model, pre-load GloVe model into keras Embedding layer:\n",
    "num_tokens = hands.W.shape[0]\n",
    "embedding_matrix = hands.W\n",
    "\n",
    "# Load GloVe embedding matrix into Keras embedding layer\n",
    "embedPretrain = Embedding(num_tokens,\n",
    "                          embedding_dim,\n",
    "                          embeddings_initializer=initializers.Constant(\n",
    "                              embedding_matrix),\n",
    "                          trainable=False)\n",
    "\n",
    "# We will use this pre-trained embedding in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word    a bon march\n",
      "pos               v\n",
      "Name: 5, dtype: object\n",
      "\n",
      "There are 56227 word/POS samples in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Let's load our smaller Moby training dataset\n",
    "\n",
    "# posdf = pd.read_csv(\"mobysmall.txt\", sep=',', header = None, names = ['word', 'pos'])\n",
    "posdf = pd.read_csv(\"normalization/mobypos_singlepos.txt\", sep=',', header = None, names = ['word', 'pos'])\n",
    "\n",
    "# Let's look at an example word\n",
    "print(posdf.iloc[5])\n",
    "\n",
    "# We'll add a column that is the GloVe 'id' for the word (or 2 for <unk>)\n",
    "posdf['id'] = posdf.loc[:,'word'].apply(lambda x: hands.vocab.word_to_id.get(x, 2))\n",
    "\n",
    "# Further eliminate all training words not already in GloVe\n",
    "validdf = posdf.loc[posdf['id'] != 2, :]\n",
    "validdf.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Count how many word samples we're left with\n",
    "print('\\nThere are {} word/POS samples in our dataset.'.format(len(validdf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 unique parts of speech labels:  ['N' 'v' 'A' 'V' 'p' 't' 'i' 'P' 'D' 'C' 'r' 'h']\n",
      "       word pos      id\n",
      "0  aardvark   N   89193\n",
      "1  aardwolf   N  331196\n",
      "2        aa   N   13479\n",
      "3     abaca   N  166697\n",
      "4     aback   v   31658\n",
      "\n",
      "POS N has 29759 examples.\n",
      "POS v has 2631 examples.\n",
      "POS A has 12069 examples.\n",
      "POS V has 5370 examples.\n",
      "POS p has 2426 examples.\n",
      "POS t has 3028 examples.\n",
      "POS i has 677 examples.\n",
      "POS P has 84 examples.\n",
      "POS D has 58 examples.\n",
      "POS C has 40 examples.\n",
      "POS r has 65 examples.\n",
      "POS h has 20 examples.\n"
     ]
    }
   ],
   "source": [
    "# Look at part of speech (POS) labels\n",
    "\n",
    "allpos = validdf['pos'].unique()\n",
    "print('There are {} unique parts of speech labels:  {}'.format(len(allpos), allpos))\n",
    "\n",
    "# Key to pos as encoded by  Moby Part-of-Speech II author, Grady Ward:\n",
    "#     Noun                    N\n",
    "#     Plural                  p\n",
    "#     Noun Phrase             h\n",
    "#     Verb (usu participle)   V\n",
    "#     Verb (transitive)       t\n",
    "#     Verb (intransitive)     i\n",
    "#     Adjective               A\n",
    "#     Adverb                  v\n",
    "#     Conjunction             C\n",
    "#     Preposition             P\n",
    "#     Interjection            !\n",
    "#     Pronoun                 r\n",
    "#     Definite Article        D\n",
    "#     Indefinite Article      I\n",
    "#     Nominative              o\n",
    "\n",
    "# Create a numeric class label for each output pos string label\n",
    "pos2label = dict(zip(allpos, range(len(allpos))))\n",
    "label2pos = dict(zip(range(len(allpos)), allpos))\n",
    "\n",
    "# The first few rows of our dataframe\n",
    "print(validdf.head())\n",
    "print()\n",
    "\n",
    "# Print number of samples in each class\n",
    "for i in range(len(allpos)):\n",
    "    pos = label2pos[i]\n",
    "    print('POS {} has {} examples.'.format(pos, len(validdf.loc[validdf['pos'] == pos, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  word: unviable,  pos label: A\n",
      "  word: sawdust,  pos label: N\n",
      "  word: exclusivity,  pos label: N\n",
      "  word: double-hung,  pos label: A\n",
      "  word: coruscant,  pos label: A\n"
     ]
    }
   ],
   "source": [
    "# Our dataset is not very balanced as there are many more nouns (N) and Adjectives (A) than other POS.\n",
    "# ...Nonetheless we can still guage accuracy fairly well given that no single class has more than\n",
    "# ...56% so even clinging to simple baseline of the dominant (N) class would give only slightly better\n",
    "# ...than a random guess.\n",
    "\n",
    "# Our model input be fed with a single word:\n",
    "n_words = 1\n",
    "x_ids = validdf['id'].to_numpy()\n",
    "# Encode each pos as a number\n",
    "y_ids = np.array([pos2label[pos] for pos in validdf['pos']])\n",
    "\n",
    "# We need to create one-hot categorical variables for labels\n",
    "x_ids = x_ids.reshape(-1,1)\n",
    "y_ids = y_ids.reshape(-1,1)\n",
    "# y_ids = tf.keras.utils.to_categorical(y_ids, num_classes = len(allpos))\n",
    "\n",
    "# Expand dims to insert dim = 1 y-class label at position 1\n",
    "# y_ids = np.expand_dims(y_ids, axis = 1)\n",
    "\n",
    "# Create training, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ids, y_ids, test_size=0.33, \n",
    "                                                    random_state=42, shuffle = True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Print out the first few examples:\n",
    "for i in range(5):\n",
    "    # print('  word: {},  pos label: {}'.format(hands.vocab.id_to_word[X_train[i][0]], label2pos[np.where(y_train[i][0]==1)[0][0]]))\n",
    "    print('  word: {},  pos label: {}'.format(hands.vocab.id_to_word[X_train[i][0]], label2pos[y_train[i][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'createOurModel'></a>\n",
    "# B. Let's create our base NN Model\n",
    "\n",
    "We've created a function which returns a model given a dict of input model params.  This will make it easier to try various modifications to the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple keras model to predict POS\n",
    "# Model parameters\n",
    "modelParams = dict(\n",
    "    batch_size = batch_size, \n",
    "    learning_rate = 0.01,\n",
    "    n_words = 1,\n",
    "    num_layers = 10,\n",
    "    H = 40,\n",
    "    hidden_initializer = 'random_uniform',\n",
    "    hidden_activation = 'sigmoid',\n",
    "    batchnorm = False,\n",
    "    output_classes = len(allpos),\n",
    "    output_initializer = 'random_uniform',\n",
    "    output_activation = 'softmax',\n",
    "    output_loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# Define a function to create our LSTM model\n",
    "def create_pos_classifier(**kwargs):\n",
    "    \n",
    "    # Read input keyword args\n",
    "    batch_size = kwargs.get('batch_size', 100) \n",
    "    learning_rate = kwargs.get('learning_rate', 0.01)\n",
    "    n_words = kwargs.get('n_words', 1)\n",
    "    num_layers = kwargs.get('num_layers', 1)\n",
    "    H = kwargs.get('H', 10)\n",
    "    hidden_initializer = kwargs.get('hidden_initializer', 'random_uniform')\n",
    "    hidden_activation = kwargs.get('hidden_activation', 'relu')\n",
    "    batchnorm = kwargs.get('batchnorm', False)\n",
    "    output_classes = kwargs.get('output_classes', 6)\n",
    "    output_initializer = kwargs.get('output_initializer', tf.keras.initializers.RandomUniform(minval=-1.0, maxval=1.0))\n",
    "    output_activation = kwargs.get('output_activation', 'softmax')\n",
    "    output_loss = kwargs.get('output_loss', tf.keras.losses.CategoricalCrossentropy())\n",
    "    metrics = kwargs.get('metrics', ['accuracy'])\n",
    "    \n",
    "    # Create an input layer for our model\n",
    "    input_ = Input(shape = (n_words,), name=\"x\")\n",
    "    \n",
    "    # Use GloVe pre-trained embeddings\n",
    "    embedPretrain = Embedding(num_tokens, embedding_dim, \n",
    "                              embeddings_initializer=initializers.Constant(embedding_matrix),\n",
    "                              trainable=False)\n",
    "    x = embedPretrain(input_)\n",
    "    \n",
    "    # Create hidden layers\n",
    "    for i in range(num_layers):\n",
    "        x = Dense(units = H, activation = None, kernel_initializer = hidden_initializer)(x)\n",
    "        if (batchnorm):\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(hidden_activation)(x)\n",
    "    \n",
    "    # Create an output layer with softmax output type\n",
    "    outlayer = Dense(units = output_classes, activation = output_activation,\n",
    "                     kernel_initializer = output_initializer)\n",
    "    yhat = outlayer(x)\n",
    "    \n",
    "    # Use Adam optimizer with our programmed learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, name='Adam')\n",
    "    \n",
    "    # Build / compile the model\n",
    "    model = Model(inputs=input_, outputs=yhat, name=\"rnn_prediction_model\")\n",
    "    model.compile(loss = output_loss, optimizer = optimizer, metrics = metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_prediction_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 1, 100)            40000300  \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1, 40)             4040      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1, 12)             492       \n",
      "=================================================================\n",
      "Total params: 40,019,592\n",
      "Trainable params: 19,292\n",
      "Non-trainable params: 40,000,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "377/377 [==============================] - 2s 3ms/step - loss: 1.4862 - accuracy: 0.5076 - val_loss: 1.4217 - val_accuracy: 0.5299\n",
      "Epoch 2/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4148 - accuracy: 0.5336 - val_loss: 1.4240 - val_accuracy: 0.5299\n",
      "Epoch 3/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.5291 - val_loss: 1.4234 - val_accuracy: 0.5299\n",
      "Epoch 4/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4198 - accuracy: 0.5299 - val_loss: 1.4239 - val_accuracy: 0.5299\n",
      "Epoch 5/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4165 - accuracy: 0.5316 - val_loss: 1.4204 - val_accuracy: 0.5299\n",
      "Epoch 6/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4200 - accuracy: 0.5283 - val_loss: 1.4180 - val_accuracy: 0.5299\n",
      "Epoch 7/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4113 - accuracy: 0.5313 - val_loss: 1.4179 - val_accuracy: 0.5299\n",
      "Epoch 8/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4033 - accuracy: 0.5331 - val_loss: 1.4255 - val_accuracy: 0.5299\n",
      "Epoch 9/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4214 - accuracy: 0.5270 - val_loss: 1.4179 - val_accuracy: 0.5299\n",
      "Epoch 10/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4229 - accuracy: 0.5268 - val_loss: 1.4175 - val_accuracy: 0.5299\n",
      "Epoch 11/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4199 - accuracy: 0.5285 - val_loss: 1.4187 - val_accuracy: 0.5299\n",
      "Epoch 12/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4132 - accuracy: 0.5308 - val_loss: 1.4201 - val_accuracy: 0.5299\n",
      "Epoch 13/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.5280 - val_loss: 1.4163 - val_accuracy: 0.5299\n",
      "Epoch 14/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4121 - accuracy: 0.5324 - val_loss: 1.4161 - val_accuracy: 0.5299\n",
      "Epoch 15/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4089 - accuracy: 0.5343 - val_loss: 1.4159 - val_accuracy: 0.5299\n",
      "Epoch 16/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4206 - accuracy: 0.5266 - val_loss: 1.4164 - val_accuracy: 0.5299\n",
      "Epoch 17/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4122 - accuracy: 0.5273 - val_loss: 1.4194 - val_accuracy: 0.5299\n",
      "Epoch 18/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4117 - accuracy: 0.5312 - val_loss: 1.4216 - val_accuracy: 0.5299\n",
      "Epoch 19/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4286 - accuracy: 0.5249 - val_loss: 1.4167 - val_accuracy: 0.5299\n",
      "Epoch 20/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4114 - accuracy: 0.5303 - val_loss: 1.4181 - val_accuracy: 0.5299\n",
      "Epoch 21/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4237 - accuracy: 0.5238 - val_loss: 1.4178 - val_accuracy: 0.5299\n",
      "Epoch 22/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4077 - accuracy: 0.5333 - val_loss: 1.4161 - val_accuracy: 0.5299\n",
      "Epoch 23/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4255 - accuracy: 0.5224 - val_loss: 1.4235 - val_accuracy: 0.5299\n",
      "Epoch 24/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4112 - accuracy: 0.5292 - val_loss: 1.4160 - val_accuracy: 0.5299\n",
      "Epoch 25/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4182 - accuracy: 0.5284 - val_loss: 1.4154 - val_accuracy: 0.5299\n",
      "Epoch 26/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4162 - accuracy: 0.5270 - val_loss: 1.4154 - val_accuracy: 0.5299\n",
      "Epoch 27/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4152 - accuracy: 0.5286 - val_loss: 1.4172 - val_accuracy: 0.5299\n",
      "Epoch 28/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4163 - accuracy: 0.5310 - val_loss: 1.4162 - val_accuracy: 0.5299\n",
      "Epoch 29/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4154 - accuracy: 0.5300 - val_loss: 1.4165 - val_accuracy: 0.5299\n",
      "Epoch 30/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.5290 - val_loss: 1.4163 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x188f19340>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model using our previous model parameter settings, show a summary and fit the model\n",
    "modelSimple = create_pos_classifier(**modelParams)\n",
    "modelSimple.summary()\n",
    "# Run a training session\n",
    "modelSimple.fit(X_train, y_train, batch_size = 100, validation_data = (X_test, y_test), epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xid: [100000]\n",
      "y_hat: [[5.4471207e-01 4.3865800e-02 2.1851785e-01 8.4867366e-02 3.9082769e-02\n",
      "  5.3260811e-02 1.1232356e-02 1.1380898e-03 1.1680303e-03 5.5763137e-04\n",
      "  1.3003853e-03 2.9683128e-04]]\n",
      "ytrue: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Categorical cross-entropy loss: 1.5208874940872192\n",
      "\n",
      "\n",
      "xid: [50133]\n",
      "y_hat: [[5.4471207e-01 4.3865800e-02 2.1851785e-01 8.4867366e-02 3.9082769e-02\n",
      "  5.3260811e-02 1.1232356e-02 1.1380898e-03 1.1680298e-03 5.5763137e-04\n",
      "  1.3003853e-03 2.9683128e-04]]\n",
      "ytrue: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Categorical cross-entropy loss: 0.6074979305267334\n",
      "\n",
      "\n",
      "xid: [36284]\n",
      "y_hat: [[5.4471207e-01 4.3865800e-02 2.1851785e-01 8.4867366e-02 3.9082769e-02\n",
      "  5.3260811e-02 1.1232356e-02 1.1380898e-03 1.1680303e-03 5.5763137e-04\n",
      "  1.3003853e-03 2.9683128e-04]]\n",
      "ytrue: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Categorical cross-entropy loss: 0.6074979305267334\n",
      "\n",
      "\n",
      "xid: [165577]\n",
      "y_hat: [[5.4471207e-01 4.3865800e-02 2.1851785e-01 8.4867366e-02 3.9082769e-02\n",
      "  5.3260811e-02 1.1232356e-02 1.1380898e-03 1.1680303e-03 5.5763137e-04\n",
      "  1.3003853e-03 2.9683128e-04]]\n",
      "ytrue: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Categorical cross-entropy loss: 1.5208874940872192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can check out our model results and see how it compares with our labels.\n",
    "# You can also directly calculate CE loss for y_hat against y.\n",
    "for xin, ytrue in list(zip(X_train[:4], y_train[:4])):\n",
    "    # xin, ytrue = batch[0].numpy(), batch[1].numpy()\n",
    "    y_hat = modelSimple.predict([xin]).reshape([1,-1])\n",
    "    print('xid: {}\\ny_hat: {}\\nytrue: {}'.format(xin, y_hat, ytrue))\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    print('Categorical cross-entropy loss: {}\\n\\n'.format(cce(ytrue, y_hat).numpy()))\n",
    "\n",
    "# We could also do an error analysis to compare what words it still gets wrong.\n",
    "# Try this as an exercise to see where the model is weakest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Top](#returnToTop) \n",
    "<a id = 'layerActivation'></a>\n",
    "# C. Layer Activations\n",
    "\n",
    "As you've learned in class, 'softmax' is used when you want to predict probabilites.  This is exactly the situation for our current example, where we are output probability for each of our 6 pos classes.  In fact, if you opted to output 'sigmoid' instead, your model would 'learn' that it can output near-0 loss by simply setting each output class to '1', thereby always hitting the correct class.  Of course it wouldn't actually be learning anything.\n",
    "\n",
    "The activation 'tanh' has an advantage over 'sigmoid' for being 0-valued at x = 0.  'relu' is also 0-valued at x = 0 and has the additional advantage of not saturating for x > 0 for helping maintain a non-zero differentiable loss function during backward propagation; you can try other choices for activation in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "377/377 [==============================] - 2s 2ms/step - loss: 1.3663 - accuracy: 0.5633 - val_loss: 0.9292 - val_accuracy: 0.6968\n",
      "Epoch 2/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.9316 - accuracy: 0.6962 - val_loss: 0.9005 - val_accuracy: 0.7100\n",
      "Epoch 3/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8978 - accuracy: 0.7133 - val_loss: 0.8732 - val_accuracy: 0.7228\n",
      "Epoch 4/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8752 - accuracy: 0.7141 - val_loss: 0.8578 - val_accuracy: 0.7174\n",
      "Epoch 5/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8341 - accuracy: 0.7226 - val_loss: 0.8398 - val_accuracy: 0.7200\n",
      "Epoch 6/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8231 - accuracy: 0.7343 - val_loss: 0.8154 - val_accuracy: 0.7470\n",
      "Epoch 7/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7906 - accuracy: 0.7573 - val_loss: 0.7953 - val_accuracy: 0.7516\n",
      "Epoch 8/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7812 - accuracy: 0.7614 - val_loss: 0.7756 - val_accuracy: 0.7635\n",
      "Epoch 9/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7614 - accuracy: 0.7691 - val_loss: 0.7703 - val_accuracy: 0.7648\n",
      "Epoch 10/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7542 - accuracy: 0.7697 - val_loss: 0.8231 - val_accuracy: 0.7472\n",
      "Epoch 11/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8002 - accuracy: 0.7498 - val_loss: 0.8468 - val_accuracy: 0.7249\n",
      "Epoch 12/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8183 - accuracy: 0.7287 - val_loss: 0.8302 - val_accuracy: 0.7228\n",
      "Epoch 13/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7982 - accuracy: 0.7357 - val_loss: 0.8021 - val_accuracy: 0.7474\n",
      "Epoch 14/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.7939 - accuracy: 0.7507 - val_loss: 0.8429 - val_accuracy: 0.7283\n",
      "Epoch 15/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8106 - accuracy: 0.7475 - val_loss: 0.8304 - val_accuracy: 0.7366\n",
      "Epoch 16/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8215 - accuracy: 0.7384 - val_loss: 0.8395 - val_accuracy: 0.7334\n",
      "Epoch 17/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8328 - accuracy: 0.7327 - val_loss: 0.8512 - val_accuracy: 0.7220\n",
      "Epoch 18/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8345 - accuracy: 0.7374 - val_loss: 0.8507 - val_accuracy: 0.7310\n",
      "Epoch 19/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8890 - accuracy: 0.7045 - val_loss: 0.8678 - val_accuracy: 0.7271\n",
      "Epoch 20/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8750 - accuracy: 0.7091 - val_loss: 0.8726 - val_accuracy: 0.7166\n",
      "Epoch 21/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.7309 - val_loss: 0.8740 - val_accuracy: 0.7132\n",
      "Epoch 22/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8407 - accuracy: 0.7316 - val_loss: 0.8334 - val_accuracy: 0.7389\n",
      "Epoch 23/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8673 - accuracy: 0.7245 - val_loss: 0.9176 - val_accuracy: 0.7233\n",
      "Epoch 24/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8948 - accuracy: 0.7288 - val_loss: 0.9477 - val_accuracy: 0.6836\n",
      "Epoch 25/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8937 - accuracy: 0.7020 - val_loss: 0.9005 - val_accuracy: 0.6973\n",
      "Epoch 26/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.9026 - accuracy: 0.6958 - val_loss: 0.8994 - val_accuracy: 0.7050\n",
      "Epoch 27/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8581 - accuracy: 0.7242 - val_loss: 0.8829 - val_accuracy: 0.7107\n",
      "Epoch 28/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8501 - accuracy: 0.7337 - val_loss: 0.8498 - val_accuracy: 0.7291\n",
      "Epoch 29/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8622 - accuracy: 0.7198 - val_loss: 0.8589 - val_accuracy: 0.7234\n",
      "Epoch 30/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.8597 - accuracy: 0.7160 - val_loss: 0.9059 - val_accuracy: 0.6973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18a883220>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams['hidden_activation'] = 'relu'  # You could also try 'tanh' or 'selu' \n",
    "# ...for Scaled Exponential Linear Unit\n",
    "modelHiddenAct = create_pos_classifier(**modelParams)\n",
    "modelHiddenAct.fit(X_train, y_train, batch_size = 100, validation_data = (X_test, y_test), epochs = 30)\n",
    "\n",
    "# If you want to see how 'sigmoid' for the output layer won't work, uncomment and try the below code:\n",
    "# modelParams['hidden_activation'] = 'relu' # reset hidden activation\n",
    "# modelParams['output_activation'] = 'sigmoid'  # This will produce bad results...  (why?)\n",
    "# modelOutputSigmoid = create_pos_classifier(**modelParams)\n",
    "# modelOutputSigmoid.fit(trainds, validation_data = testds, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Top](#returnToTop) \n",
    "<a id = 'initializationFunctions'></a>\n",
    "# D. Weight Initialization\n",
    "\n",
    "Weight initialization is another important tool for avoiding exploding, vanishing gradients problem.\n",
    "In the deep neural net early days, random uniform initialization of weights was common.  There appeared to be two problems:  (1) gradients could end up vanishing (or exploding) as they were calculated in moving from layer output to input and (2) signals could end up vanishing (or exploding) as they propagated from input to output in a forward direction through the layer.  \n",
    "\n",
    "A ground-breaking paper presented by Glorot and Bengio in 2010  (http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) described a way to initialize weights so as to avoid vanishing or exploding signals during inference and likewise to minimize vanishing/exploding gradients during backward propagation.  The goal is to keep input and output variance equal as well as output and input gradient variance.  Out of the paper was born 'Xavier' initialization (also known as 'Glorot uniform'.)\n",
    "\n",
    "Soon afterwards, the 'relu' activation function was seen to be an effective way to avoid moving the signal mean away from 0, as well as mitigating signal saturation.  At the same time, [the 'He' initialization introduced in this 2015 paper by He et al](https://arxiv.org/pdf/1502.01852v1.pdf) was presented as an improvement over 'Xavier' when using 'relu' activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "377/377 [==============================] - 2s 2ms/step - loss: 1.0606 - accuracy: 0.6615 - val_loss: 0.6943 - val_accuracy: 0.7826\n",
      "Epoch 2/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6987 - accuracy: 0.7853 - val_loss: 0.6643 - val_accuracy: 0.7915\n",
      "Epoch 3/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6600 - accuracy: 0.7988 - val_loss: 0.6894 - val_accuracy: 0.7961\n",
      "Epoch 4/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.8095 - val_loss: 0.6773 - val_accuracy: 0.7991\n",
      "Epoch 5/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6277 - accuracy: 0.8082 - val_loss: 0.6645 - val_accuracy: 0.7968\n",
      "Epoch 6/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6226 - accuracy: 0.8098 - val_loss: 0.6418 - val_accuracy: 0.8004\n",
      "Epoch 7/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.8188 - val_loss: 0.6423 - val_accuracy: 0.8010\n",
      "Epoch 8/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.8229 - val_loss: 0.6671 - val_accuracy: 0.7923\n",
      "Epoch 9/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.8215 - val_loss: 0.6636 - val_accuracy: 0.7935\n",
      "Epoch 10/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.8157 - val_loss: 0.6689 - val_accuracy: 0.7947\n",
      "Epoch 11/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5823 - accuracy: 0.8183 - val_loss: 0.6471 - val_accuracy: 0.7995\n",
      "Epoch 12/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.8179 - val_loss: 0.6490 - val_accuracy: 0.8029\n",
      "Epoch 13/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.8198 - val_loss: 0.6489 - val_accuracy: 0.7979\n",
      "Epoch 14/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.8225 - val_loss: 0.6565 - val_accuracy: 0.7961\n",
      "Epoch 15/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.8212 - val_loss: 0.6471 - val_accuracy: 0.8017\n",
      "Epoch 16/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5821 - accuracy: 0.8215 - val_loss: 0.6644 - val_accuracy: 0.8004\n",
      "Epoch 17/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.8234 - val_loss: 0.6637 - val_accuracy: 0.7933\n",
      "Epoch 18/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.8234 - val_loss: 0.6491 - val_accuracy: 0.7933\n",
      "Epoch 19/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.8190 - val_loss: 0.6593 - val_accuracy: 0.7971\n",
      "Epoch 20/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.8246 - val_loss: 0.6556 - val_accuracy: 0.7927\n",
      "Epoch 21/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.8261 - val_loss: 0.6791 - val_accuracy: 0.7925\n",
      "Epoch 22/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5875 - accuracy: 0.8208 - val_loss: 0.7198 - val_accuracy: 0.7938\n",
      "Epoch 23/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6450 - accuracy: 0.8126 - val_loss: 0.7432 - val_accuracy: 0.7701\n",
      "Epoch 24/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.8009 - val_loss: 0.7299 - val_accuracy: 0.7533\n",
      "Epoch 25/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6795 - accuracy: 0.7802 - val_loss: 0.6941 - val_accuracy: 0.7870\n",
      "Epoch 26/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6274 - accuracy: 0.8082 - val_loss: 0.6820 - val_accuracy: 0.7902\n",
      "Epoch 27/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.8138 - val_loss: 0.7251 - val_accuracy: 0.7754\n",
      "Epoch 28/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6456 - accuracy: 0.8006 - val_loss: 0.6738 - val_accuracy: 0.7921\n",
      "Epoch 29/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.8130 - val_loss: 0.7036 - val_accuracy: 0.7807\n",
      "Epoch 30/30\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.6296 - accuracy: 0.8066 - val_loss: 0.6745 - val_accuracy: 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18abc7190>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams['hidden_activation'] = 'relu'  \n",
    "modelParams['hidden_initializer'] = 'he_uniform' # He uniform initialization works better for relu\n",
    "modelParams['output_initializer'] = 'he_uniform'\n",
    "modelHeInit = create_pos_classifier(**modelParams)\n",
    "modelHeInit.fit(X_train, y_train, batch_size = 100, validation_data = (X_test, y_test), epochs = 30)\n",
    "\n",
    "# You can also use LeCun initialization when using the SELU activation\n",
    "# modelParams['hidden_activation'] = 'selu'  \n",
    "# modelParams['output_initializer'] = 'lecun_normal' # LeCun initialization works better for selu\n",
    "# modelLeCunInit = create_pos_classifier(**modelParams)\n",
    "# modelLeCunInit.fit(trainds, validation_data = testds, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'optimizers'></a>\n",
    "## E. Optimizers\n",
    "\n",
    "For training steps, you can use any optimizer, but we recommend `tf.train.AdamOptimizer` with gradient clipping (`tf.clip_by_global_norm`).  Adam adjusts the learning rate on a per-variable basis, and also adds a \"momentum\" term that improves the speed of convergence. See [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/) for more.\n",
    "\n",
    "For training with AdamOptimizer, a good value is `learning_rate = 0.01` as defined under \"Training Parameters\" (next to batch size, num epochs, etc.). If you use `learning_rate = 0.1` with Adam, the model will likely overfit or training may be unstable. (However, 0.1 works well with Adagrad and vanilla SGD.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "<a id = 'batchNormalization'></a>\n",
    "# F. Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas having good initialization of weights helps avoid gradient exploding / vanishing at the beginning of training, a technique called *batch normalization* helps maintain zero-mean / unity-variance of layer inputs during training.  \n",
    "\n",
    "The technique involves computing a mean and standard deviation (averaged over the batch) for each input feature and using the mean and standard deviation vectors to normalize each feature.  Two additional learned parameters (beta and gamma) are used to further scale and shift the inputs to help maintain zero-offset.  \n",
    "\n",
    "![Batch Normalization equations](./normalization/batch_normalization_equations.png)\n",
    "\n",
    "The technique was presented in a 2015 paper by Ioffe and Szegedy (http://proceedings.mlr.press/v37/ioffe15.pdf).  \n",
    "\n",
    "Keras provides a Batch Normalization layer which can be placed after hidden layers (or even after the Input() layer) to take care of this scaling / shifting.\n",
    "\n",
    "Batch normalization tends to lengthen per-batch training computation time due to the requirement of computing batch means and batch variances.  The trade-off is that the quality of each training cycle tends to be better (by keeping layer inputs well-conditioned via scaling / shifting) which tends to have a net effect of improving the rate of accuracy improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_prediction_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1, 100)            40000300  \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1, 40)             4040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1, 40)             1640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1, 40)             0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1, 12)             492       \n",
      "=================================================================\n",
      "Total params: 40,021,192\n",
      "Trainable params: 20,092\n",
      "Non-trainable params: 40,001,100\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "377/377 [==============================] - 4s 5ms/step - loss: 1.0564 - accuracy: 0.6516 - val_loss: 1.8648 - val_accuracy: 0.5302\n",
      "Epoch 2/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.8162 - accuracy: 0.7378 - val_loss: 2.1947 - val_accuracy: 0.5369\n",
      "Epoch 3/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.7386 - accuracy: 0.7654 - val_loss: 0.8074 - val_accuracy: 0.7526\n",
      "Epoch 4/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6958 - accuracy: 0.7793 - val_loss: 0.7733 - val_accuracy: 0.7732\n",
      "Epoch 5/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6760 - accuracy: 0.7861 - val_loss: 1.0220 - val_accuracy: 0.7335\n",
      "Epoch 6/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6692 - accuracy: 0.7918 - val_loss: 0.9734 - val_accuracy: 0.7293\n",
      "Epoch 7/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6585 - accuracy: 0.7957 - val_loss: 0.8715 - val_accuracy: 0.7247\n",
      "Epoch 8/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.8016 - val_loss: 0.9698 - val_accuracy: 0.7274\n",
      "Epoch 9/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.8019 - val_loss: 1.2770 - val_accuracy: 0.6383\n",
      "Epoch 10/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.8050 - val_loss: 1.2583 - val_accuracy: 0.6244\n",
      "Epoch 11/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.8036 - val_loss: 0.9265 - val_accuracy: 0.7120\n",
      "Epoch 12/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.6062 - accuracy: 0.8105 - val_loss: 1.0109 - val_accuracy: 0.6949\n",
      "Epoch 13/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5975 - accuracy: 0.8133 - val_loss: 0.8080 - val_accuracy: 0.7658\n",
      "Epoch 14/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5832 - accuracy: 0.8137 - val_loss: 1.1520 - val_accuracy: 0.6665\n",
      "Epoch 15/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5881 - accuracy: 0.8150 - val_loss: 1.2260 - val_accuracy: 0.7156\n",
      "Epoch 16/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5812 - accuracy: 0.8134 - val_loss: 1.5552 - val_accuracy: 0.6698\n",
      "Epoch 17/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.8231 - val_loss: 1.3353 - val_accuracy: 0.6614\n",
      "Epoch 18/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5735 - accuracy: 0.8184 - val_loss: 0.7477 - val_accuracy: 0.7645\n",
      "Epoch 19/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5757 - accuracy: 0.8175 - val_loss: 0.6613 - val_accuracy: 0.7944\n",
      "Epoch 20/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5590 - accuracy: 0.8214 - val_loss: 1.2554 - val_accuracy: 0.6518\n",
      "Epoch 21/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5558 - accuracy: 0.8240 - val_loss: 1.0551 - val_accuracy: 0.7200\n",
      "Epoch 22/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5362 - accuracy: 0.8279 - val_loss: 1.5623 - val_accuracy: 0.6201\n",
      "Epoch 23/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5406 - accuracy: 0.8259 - val_loss: 1.4357 - val_accuracy: 0.6899\n",
      "Epoch 24/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.8295 - val_loss: 0.7726 - val_accuracy: 0.7513\n",
      "Epoch 25/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5336 - accuracy: 0.8271 - val_loss: 0.9201 - val_accuracy: 0.7399\n",
      "Epoch 26/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.8272 - val_loss: 0.9685 - val_accuracy: 0.7334\n",
      "Epoch 27/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.8296 - val_loss: 1.1570 - val_accuracy: 0.6665\n",
      "Epoch 28/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.8278 - val_loss: 0.6695 - val_accuracy: 0.7963\n",
      "Epoch 29/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8281 - val_loss: 0.9075 - val_accuracy: 0.6998\n",
      "Epoch 30/30\n",
      "377/377 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.8336 - val_loss: 1.1483 - val_accuracy: 0.6245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1892c6a60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify model to enable Batch Normalization layer\n",
    "modelParams['batchnorm'] = True\n",
    "modelSimple = create_pos_classifier(**modelParams)\n",
    "modelSimple.summary()  # To see that batch normalization has been added\n",
    "# Run a training session\n",
    "modelSimple.fit(X_train, y_train, batch_size = 100, validation_data = (X_test, y_test), epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "<a id = 'errorAnalysis'></a>\n",
    "# G. Bonus section:  Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is insightful to look at classification models to determine if systematic problems are happening that might cause a certain class to be under-predicted.  This might help find problems in the model, or suggest feature modifications for instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37672,)\n",
      "(37672,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "y_true = y_train.squeeze()\n",
    "y_pred = modelSimple(X_train).numpy().argmax(axis=-1).squeeze()\n",
    "# print(y_pred.argmax(axis=-1))\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "cm = confusion_matrix(y_true, y_pred, normalize = 'true')\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=[label2pos[i] for i in range(12)]).plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 class is N\n",
      "1 class is v\n",
      "2 class is A\n",
      "3 class is V\n",
      "4 class is p\n",
      "5 class is t\n",
      "6 class is i\n",
      "7 class is P\n",
      "8 class is D\n",
      "9 class is C\n",
      "10 class is r\n",
      "11 class is h\n"
     ]
    }
   ],
   "source": [
    "# What are the classes?\n",
    "for i in range(12):\n",
    "    print('{} class is {}'.format(i, label2pos[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
