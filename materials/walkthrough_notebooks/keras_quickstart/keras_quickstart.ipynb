{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae52109f",
   "metadata": {},
   "source": [
    "<a id = 'top'></a>\n",
    "\n",
    "# A quick-start guide to Keras\n",
    "  * A. [What is Keras?](#introToKeras) \n",
    "  * B. [Basic Operations](#kerasBasicOps)  \n",
    "      * 1. [Sequential interface](#sequentialInterface)\n",
    "      * 2. [Creating a model](#createModel)\n",
    "      * 3. [Compiling a model](#compileModel)\n",
    "      * 4. [Training a model](#trainModel)\n",
    "      * 5. [Saving a model](#saveModel)\n",
    "      * 6. [Reloading a model](#reloadModel)\n",
    "  * C. [Defining your model inside a function to add flexibility](#functionWrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40381e7",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'introToKeras'></a>\n",
    "## A. What is Keras?\n",
    "\n",
    "[Keras](https://en.wikipedia.org/wiki/Keras) is a front-end interface to Tensorflow.  Keras has its own [documentation](https://keras.io/about/) and is also well-documented in [tensorflow keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras).  \n",
    "\n",
    "Using the Keras interface greatly simplifies the task of constructing, training and using tensorflow models.  In this notebook we'll build and train a basic fully-connected neural net and learn some of the important operations available within Keras.  We'll use the [sequential-model syntax](https://keras.io/guides/sequential_model/), which is useful when becoming familiar with Keras and appropriate for models where each layer has a single output feeding sequentially to the next layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9968fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173c3af",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'kerasBasicOps'></a>\n",
    "## B. Basic Operations in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478a88b",
   "metadata": {},
   "source": [
    "1. Construct the model graph from model input, model layers\n",
    "2. Build the model (from input, output of the graph)\n",
    "3. Compile the model with optimizer, metric set, loss function\n",
    "4. Fit the model / evaluate the model\n",
    "5. Save the model and re-use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa486a4",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'sequentialInterface'></a>\n",
    "### B1. Sequential interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745fe1a",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'createModel'></a>\n",
    "### B2. Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec176bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 200\n",
    "model = keras.Sequential(\n",
    "    [keras.Input(shape=(2,)),\n",
    "     keras.layers.Dense(200, activation=\"relu\", name=\"h1_layer\"),\n",
    "     keras.layers.Dense(100, activation=\"relu\", name=\"h2_layer\"),\n",
    "     keras.layers.Dense(2, activation=\"sigmoid\", name=\"output_layer\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473899d",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'compileModel'></a>\n",
    "### B3. Compiling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer, and accuracy\n",
    "# Here we're using some basic loss, optimizer, metrics provided by Keras, all of which use reasonable defaults.\n",
    "\n",
    "# However if you want to adjust things like learning rate you'll want to use the full Keras functional version of these to have ability to change\n",
    "# ... the arguments from their default values.\n",
    "\n",
    "loss = \"sparse_categorical_crossentropy\"    # Using sparse crossentropy when your class values are defined by unique labels.  Alternatively, using\n",
    "#                                             ...categorical_crossentropy requires your labels to be in one-hot vector format.\n",
    "optimizer = \"adam\"       # adam is an optimizer we'll use a lot\n",
    "metrics = [\"sparse_categorical_accuracy\"] # This is a better accuracy metric to use\n",
    "# ...as there is a bug in \"accuracy\" metric preventing re-loaded model from calculating \n",
    "# ...correct accuracy\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad5730",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'trainModel'></a>\n",
    "### B4. Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57b3d3",
   "metadata": {},
   "source": [
    "#### Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some data and labels:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "nrotate =  6\n",
    "size = 2040\n",
    "theta = np.linspace(start = 0, stop = nrotate * 2 * np.pi, num = size)\n",
    "len(theta)\n",
    "r = 1/(nrotate * 2 * np.pi) * theta\n",
    "x = r * np.cos(theta)\n",
    "y = r * np.sin(theta)\n",
    "# Toggle the below line to see the dividing line between groups\n",
    "plt.plot(x, y)\n",
    "# thickness = 1/(nrotate * 2 * np.pi) * 2 pi = 1 / nrotate\n",
    "1 / nrotate * np.random.uniform(size = 100)\n",
    "eps = 0.8\n",
    "nparts = 4\n",
    "colors = []\n",
    "for i in range(nparts):\n",
    "    colors.extend(['r']*int(size / (2*nparts)) + ['b']*int(size / (2*nparts)))\n",
    "labels = ['r']*int(size/nparts) + ['b']*int(size/nparts)+['r']*int(size/nparts) + ['b']*int(size/nparts)\n",
    "rjitter = r - eps / nrotate * np.random.uniform(size = size)\n",
    "xjitter = rjitter*np.cos(theta)\n",
    "yjitter = rjitter*np.sin(theta)\n",
    "plt.scatter(xjitter, yjitter, color = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Convert our data to numpy arrays with correct shapes for our model input, output\n",
    "datain = np.transpose(np.vstack([x,y]))\n",
    "labels = np.array([1 if color=='b' else 0 for color in colors]).reshape([-1,1])\n",
    "\n",
    "# Create training, eval split\n",
    "train_input, test_input, train_labels, test_labels = train_test_split(datain, labels, test_size = 0.2, \n",
    "                                                         random_state = 41,\n",
    "                                                         shuffle = True)\n",
    "# Train the model using our training input, labels\n",
    "## the validation_split arguments states that 20% of the training data is to be used\n",
    "## ...as dev data.\n",
    "model.fit(train_input, train_labels, batch_size = 400, validation_split=0.2, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d712525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the data with our test_input, test_labels\n",
    "model.evaluate(test_input, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42829063",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'saveModel'></a>\n",
    "### B5. Saving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"./keras_qs_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e64151",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'reloadModel'></a>\n",
    "### B6. Reloading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that reloaded model evaluates to same score as when we saved it originally.\n",
    "model2 = keras.models.load_model(\"./keras_qs_model\")\n",
    "model2.evaluate(train_input, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee1753",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'functionWrapper'></a>\n",
    "## C. Defining your model inside a function to add flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63356b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to re-run your model with different settings and hyper-parameters there's a good chance you'll benefit by using a class definition.\n",
    "\n",
    "# Define parameters in a dictionary\n",
    "modelparams = dict(\n",
    "    layers = ( (200, 'relu'), (100, 'relu') ), \n",
    "    n_classes = 2, # number of output classes -- 2 for binary\n",
    "    learning_rate = 0.01, \n",
    "    output_activation = \"sigmoid\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"adam\",\n",
    "    metrics = [\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "def basic_km(**kwargs):\n",
    "    layers = kwargs.get('layers', ((10, 'relu')) ) \n",
    "    n_classes = kwargs.get('n_classes', 2)\n",
    "    learning_rate = kwargs.get('learning_rate', 0.01)\n",
    "    output_activation = kwargs.get('output_activation', \"sigmoid\")\n",
    "    optimizer = kwargs.get('optimizer', \"adam\")\n",
    "    loss = kwargs.get('loss', \"categorical_crossentropy\")\n",
    "    metrics = kwargs.get('metrics', [\"accuracy\"])\n",
    "    \n",
    "    num_layers = len(layers)\n",
    "    \n",
    "    graph = []\n",
    "    # Define input shape\n",
    "    graph.append(keras.Input(shape=(2,)))\n",
    "    # Add hidden layers\n",
    "    for i, layer in enumerate(layers):\n",
    "        graph.append(keras.layers.Dense(layer[0], activation = layer[1], name = \"h\" + str(i+1) + \"layer\"   ))\n",
    "    # Add output layer\n",
    "    graph.append(keras.layers.Dense(n_classes, activation = output_activation, name=\"output_layer\"))\n",
    "    \n",
    "    # Define a sequential model from inputs and outputs of graph\n",
    "    model = keras.Sequential(graph)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    return model\n",
    "\n",
    "modelFromDef = basic_km(**modelparams)\n",
    "\n",
    "# Train model \n",
    "modelFromDef.fit(train_input, train_labels, batch_size = 400, validation_split=0.2, epochs = 300)    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
